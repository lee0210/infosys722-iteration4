{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3117901-874c-4979-9551-0b2f597f3ad4",
   "metadata": {},
   "source": [
    "## INFOSYS 722 Assignement Iteration 4 - Sub-iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0307248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a4d98d-8000-4070-8d6e-d6d1501f4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77edb78b-f681-48dd-ac1e-eb26458ddefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/11 18:59:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('infosys722-i4-i2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635d7fa6-c616-4326-87b8-1f417f6d9c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "integrated_purchase_detail = spark.read.options(compression='gzip').format('parquet').load(\n",
    "    './Ready Datasets/purchase_detail_v001')\n",
    "integrated_sales = spark.read.options(compression='gzip').format('parquet').load(\n",
    "    './Ready Datasets/sales_v001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a70075e-ab29-46e4-904c-344b5e050496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|     SalesQuantity|\n",
      "+-------+------------------+\n",
      "|  count|             36962|\n",
      "|   mean|1.9354201612466857|\n",
      "| stddev|1.4654083220779113|\n",
      "|    min|                 1|\n",
      "|    max|                 8|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_extreme_by_z_scores(dataframe, column, threshold = 1):\n",
    "    mean, std = dataframe.agg(F.mean(column), F.stddev(column)).collect()[0]\n",
    "    dataframe = dataframe.withColumn('z_scores', (F.col(column) - mean) / std)\n",
    "    return dataframe.where(F.col('z_scores') <= threshold).drop('z_scores')\n",
    "\n",
    "integrated_sales = remove_extreme_by_z_scores(integrated_sales, 'SalesQuantity')\n",
    "integrated_sales.describe('SalesQuantity').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0e8e1-6adc-466c-bd0a-b2f593a14304",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dae7a45-df9d-4e52-8be4-8d74ddf5551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor, LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, NaiveBayes, GBTClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e1c628-8981-40e6-83c1-d74ae246daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression_model(result, labelCol, predictionCol='prediction', metrics = ['rmse', 'mse', 'mae', 'r2']):\n",
    "    results = [(metric, \n",
    "                RegressionEvaluator(labelCol=labelCol, metricName=metric, predictionCol=predictionCol).evaluate(result)) \n",
    "               for metric in metrics]\n",
    "    for metric, result in results:\n",
    "        print(f'{metric}: {result}')\n",
    "    return dict(results)\n",
    "\n",
    "def evaluate_classification_model(result, labelCol, predictionCol='prediction', metrics = ['f1', 'accuracy']):\n",
    "    results = [(metric, \n",
    "                MulticlassClassificationEvaluator(\n",
    "                    labelCol=labelCol, metricName=metric, predictionCol=predictionCol).evaluate(result)) \n",
    "               for metric in metrics]\n",
    "    for metric, v in results:\n",
    "        print(f'{metric}: {v}')\n",
    "    return dict(results)\n",
    "    \n",
    "def get_string_indexers(dataframe, suffix='_index'):\n",
    "    indexers = []\n",
    "    for feature, dtype in dataframe.dtypes:\n",
    "        if dtype == 'string':\n",
    "            indexers.append(StringIndexer(inputCol=feature, outputCol=feature + suffix))\n",
    "    return indexers\n",
    "\n",
    "def generate_baseline(dataframe, target):\n",
    "    target_mean = dataframe.agg(F.mean(target)).collect()[0][0]\n",
    "    return dataframe.withColumn('baseline_prediction', F.lit(target_mean))\n",
    "\n",
    "def balance(dataframe, target, size=None):\n",
    "    categories = dataframe.groupBy(target).agg(F.count(target).alias('count'))\n",
    "    if size is None:\n",
    "        size = int(categories.agg(F.mean('count')).collect()[0][0])\n",
    "    balanced_df = spark.createDataFrame([], dataframe.schema)\n",
    "    for category, count in categories.collect():\n",
    "        if count > size:\n",
    "            sample = dataframe.where(F.col(target) == category).orderBy(F.rand(13)).limit(size)\n",
    "        else:\n",
    "            ratio = math.ceil(size/count)\n",
    "            sample = dataframe.where(F.col(target) == category).withColumn(\n",
    "                'dummy', F.explode(F.array([F.lit(i) for i in range(ratio)]))).drop('dummy').orderBy(F.rand(13)).limit(size)\n",
    "        balanced_df = balanced_df.unionAll(sample)\n",
    "    return balanced_df\n",
    "\n",
    "def print_evaluation(model, train, test, target, transformer, evaluate_function=evaluate_regression_model):\n",
    "    print('Training data evaluation metrics:')\n",
    "    result = model.transform(transformer.transform(train))\n",
    "    evaluate_function(result, target)\n",
    "\n",
    "    print('Testing data evaluation metrics:')\n",
    "    result = model.transform(transformer.transform(test))\n",
    "    evaluate_function(result, target)\n",
    "\n",
    "def print_feature_importance(model, train, rounding=6):\n",
    "    attrs = train.schema[\"features\"].metadata['ml_attr']['attrs']\n",
    "    feature_names = []\n",
    "    for key, feature_list in attrs.items():\n",
    "        feature_names = feature_names + feature_list\n",
    "    feature_importances = [(f['name'], float(round(model.featureImportances[f['idx']], rounding))) for f in feature_names]\n",
    "    spark.createDataFrame(feature_importances, ['feature', 'importance']).orderBy('importance', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce2ae86-8a69-400e-9ac3-c713dd787dfc",
   "metadata": {},
   "source": [
    "### Compare Algorithm Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c9e2d1-422a-4a39-83ec-cf7b860ca826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = integrated_sales.randomSplit([0.7, 0.3], seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2215070b-a573-4f11-8661-d7db566def1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train.toPandas()['SalesQuantity'], bins=[i+0.5 for i in range(0, 9)], rwidth=0.5, alpha=0.5, label='train')\n",
    "balanced_train = balance(train, 'SalesQuantity')\n",
    "plt.hist(balanced_train.toPandas()['SalesQuantity'], bins=[i+0.5 for i in range(0, 9)], rwidth=0.5, alpha=0.5, label='balanced')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b579b72-7cb0-4dd4-99a5-e0a66ce47070",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = balanced_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89fda14f-f264-4faa-8c6c-dd95e0fcedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_pipeline = Pipeline(stages=get_string_indexers(integrated_sales) + [\n",
    "    VectorAssembler(inputCols=[\n",
    "        'SalesPrice', 'DayOfMonth', 'PurchasePrice',\n",
    "        'VendorNumber_index', 'DayOfWeek_index'], \n",
    "                    outputCol='features')\n",
    "])\n",
    "transformer = transformation_pipeline.fit(integrated_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b7b175-f13b-4a29-b2c7-db729ddac2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 331:============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.3219338027301448\n",
      "accuracy: 0.34083564173591874\n",
      "Testing data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.27910822674147456\n",
      "accuracy: 0.22051048313582497\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dtr = DecisionTreeClassifier(maxDepth=10, labelCol='SalesQuantity', featuresCol='features', maxBins=256)\n",
    "model = dtr.fit(transformer.transform(train))\n",
    "print_evaluation(model, train, test, 'SalesQuantity', transformer, evaluate_function=evaluate_classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17ad24a3-bd95-4e3b-abb6-7505dfb51748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:39:02 WARN DAGScheduler: Broadcasting large task binary with size 1432.6 KiB\n",
      "23/10/11 02:39:06 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:39:10 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:39:17 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/10/11 02:39:19 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.5380134973292834\n",
      "accuracy: 0.550284702985534\n",
      "Testing data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:39:21 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/10/11 02:39:22 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.32015204277127285\n",
      "accuracy: 0.2577939835916135\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rfr = RandomForestClassifier(maxDepth=10, labelCol='SalesQuantity', featuresCol='features', maxBins=256)\n",
    "model = rfr.fit(transformer.transform(train))\n",
    "print_evaluation(model, train, test, 'SalesQuantity', transformer, evaluate_function=evaluate_classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f4e8cd7-1e51-401e-a98a-526bf244c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:39:25 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/10/11 02:39:25 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.06965653539413372\n",
      "accuracy: 0.09256694367497692\n",
      "Testing data evaluation metrics:\n",
      "f1: 0.13922327723036076\n",
      "accuracy: 0.09726526891522333\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb = NaiveBayes(labelCol='SalesQuantity', featuresCol='features')\n",
    "model = nb.fit(transformer.transform(train))\n",
    "print_evaluation(model, train, test, 'SalesQuantity', transformer, evaluate_function=evaluate_classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "470eeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_pipeline = Pipeline(stages=get_string_indexers(integrated_sales) + [\n",
    "    VectorAssembler(inputCols=[\n",
    "        'SalesPrice_log10', 'DayOfMonth', 'PurchasePrice_log10',\n",
    "        'VendorNumber_index', 'DayOfWeek_index'], \n",
    "                    outputCol='features')\n",
    "])\n",
    "transformer = transformation_pipeline.fit(integrated_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ff25790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.3219338027301448\n",
      "accuracy: 0.34083564173591874\n",
      "Testing data evaluation metrics:\n",
      "f1: 0.27910822674147456\n",
      "accuracy: 0.22051048313582497\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dtr = DecisionTreeClassifier(maxDepth=10, labelCol='SalesQuantity', featuresCol='features', maxBins=256)\n",
    "model = dtr.fit(transformer.transform(train))\n",
    "print_evaluation(model, train, test, 'SalesQuantity', transformer, evaluate_function=evaluate_classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b81274a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:39:54 WARN DAGScheduler: Broadcasting large task binary with size 1432.0 KiB\n",
      "23/10/11 02:39:57 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:40:02 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:40:09 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/10/11 02:40:11 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.5380134973292834\n",
      "accuracy: 0.550284702985534\n",
      "Testing data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:40:13 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/10/11 02:40:13 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.3203502142355919\n",
      "accuracy: 0.25797629899726526\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rfr = RandomForestClassifier(maxDepth=10, labelCol='SalesQuantity', featuresCol='features', maxBins=256)\n",
    "model = rfr.fit(transformer.transform(train))\n",
    "print_evaluation(model, train, test, 'SalesQuantity', transformer, evaluate_function=evaluate_classification_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfd0ef-fa22-4323-b4e0-47500e5ca8c6",
   "metadata": {},
   "source": [
    "### Data Mining - Sales Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15cdce2a-e23f-4e3c-b7ee-16bda8b2a446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size is 0.3090169943749474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "transformation_pipeline = Pipeline(stages=get_string_indexers(integrated_sales) + [\n",
    "    VectorAssembler(inputCols=[\n",
    "        'SalesPrice', 'DayOfMonth', 'PurchasePrice',\n",
    "        'VendorNumber_index', 'DayOfWeek_index'], \n",
    "                    outputCol='features')\n",
    "])\n",
    "transformer = transformation_pipeline.fit(integrated_sales)\n",
    "\n",
    "test_data_size = 1 / (math.sqrt(5) + 1)\n",
    "print(f'Test data size is {test_data_size}')\n",
    "train, test = integrated_sales.randomSplit([1-test_data_size, test_data_size], seed=13)\n",
    "train = balance(train, 'SalesQuantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80f0505f-a81e-4f91-84e7-b3ded6708853",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "def try_depth(max_depth):\n",
    "    if cache.get(max_depth) is not None:\n",
    "        return cache.get(max_depth)\n",
    "    print('===============================================')\n",
    "    print(f'Trying maxDepth: {max_depth}')\n",
    "    rfr = RandomForestClassifier(maxDepth=max_depth, labelCol='SalesQuantity', featuresCol='features', maxBins=256)\n",
    "    model = rfr.fit(transformer.transform(train))\n",
    "    print('training:')\n",
    "    result = model.transform(transformer.transform(train))\n",
    "    _ = evaluate_classification_model(result, 'SalesQuantity')\n",
    "    print('testing:')\n",
    "    result = model.transform(transformer.transform(test))\n",
    "    cache[max_depth] = evaluate_classification_model(result, 'SalesQuantity')\n",
    "    return cache[max_depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806665a2-9856-418b-85bc-39b780a0e62d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Trying maxDepth: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:26:04 WARN DAGScheduler: Broadcasting large task binary with size 1420.2 KiB\n",
      "23/10/11 02:26:09 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:26:15 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/10/11 02:26:23 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/10/11 02:26:24 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.33074929344408865\n",
      "accuracy: 0.27016520894071916\n",
      "===============================================\n",
      "Trying maxDepth: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:26:43 WARN DAGScheduler: Broadcasting large task binary with size 1420.2 KiB\n",
      "23/10/11 02:26:46 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:26:51 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/10/11 02:26:57 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/10/11 02:27:06 WARN DAGScheduler: Broadcasting large task binary with size 7.2 MiB\n",
      "23/10/11 02:27:17 WARN DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n",
      "23/10/11 02:27:25 WARN DAGScheduler: Broadcasting large task binary with size 1195.6 KiB\n",
      "23/10/11 02:27:31 WARN DAGScheduler: Broadcasting large task binary with size 13.1 MiB\n",
      "23/10/11 02:27:40 WARN DAGScheduler: Broadcasting large task binary with size 1370.6 KiB\n",
      "23/10/11 02:27:48 WARN DAGScheduler: Broadcasting large task binary with size 16.8 MiB\n",
      "23/10/11 02:28:00 WARN DAGScheduler: Broadcasting large task binary with size 1506.9 KiB\n",
      "23/10/11 02:28:08 WARN DAGScheduler: Broadcasting large task binary with size 20.8 MiB\n",
      "23/10/11 02:28:21 WARN DAGScheduler: Broadcasting large task binary with size 1529.2 KiB\n",
      "23/10/11 02:28:29 WARN DAGScheduler: Broadcasting large task binary with size 24.8 MiB\n",
      "23/10/11 02:28:44 WARN DAGScheduler: Broadcasting large task binary with size 1537.5 KiB\n",
      "23/10/11 02:28:53 WARN DAGScheduler: Broadcasting large task binary with size 28.9 MiB\n",
      "23/10/11 02:29:05 WARN DAGScheduler: Broadcasting large task binary with size 1482.8 KiB\n",
      "23/10/11 02:29:15 WARN DAGScheduler: Broadcasting large task binary with size 32.7 MiB\n",
      "23/10/11 02:29:28 WARN DAGScheduler: Broadcasting large task binary with size 1359.2 KiB\n",
      "23/10/11 02:29:37 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "23/10/11 02:29:49 WARN DAGScheduler: Broadcasting large task binary with size 1192.3 KiB\n",
      "23/10/11 02:29:54 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/10/11 02:29:55 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/10/11 02:29:58 WARN DAGScheduler: Broadcasting large task binary with size 23.9 MiB\n",
      "23/10/11 02:30:01 WARN DAGScheduler: Broadcasting large task binary with size 23.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.35158873646285366\n",
      "accuracy: 0.3051506316812439\n",
      "===============================================\n",
      "Trying maxDepth: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:30:18 WARN DAGScheduler: Broadcasting large task binary with size 1420.2 KiB\n",
      "23/10/11 02:30:21 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:30:25 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/10/11 02:30:32 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/10/11 02:30:40 WARN DAGScheduler: Broadcasting large task binary with size 7.2 MiB\n",
      "23/10/11 02:30:51 WARN DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n",
      "23/10/11 02:30:59 WARN DAGScheduler: Broadcasting large task binary with size 1195.6 KiB\n",
      "23/10/11 02:31:06 WARN DAGScheduler: Broadcasting large task binary with size 13.1 MiB\n",
      "23/10/11 02:31:15 WARN DAGScheduler: Broadcasting large task binary with size 1370.6 KiB\n",
      "23/10/11 02:31:23 WARN DAGScheduler: Broadcasting large task binary with size 16.8 MiB\n",
      "23/10/11 02:31:34 WARN DAGScheduler: Broadcasting large task binary with size 1506.9 KiB\n",
      "23/10/11 02:31:43 WARN DAGScheduler: Broadcasting large task binary with size 12.4 MiB\n",
      "23/10/11 02:31:45 WARN DAGScheduler: Broadcasting large task binary with size 12.4 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.33863616737072755\n",
      "accuracy: 0.2844774273345702\n",
      "===============================================\n",
      "Trying maxDepth: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:32:01 WARN DAGScheduler: Broadcasting large task binary with size 1420.2 KiB\n",
      "23/10/11 02:32:04 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:32:08 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/10/11 02:32:14 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/10/11 02:32:23 WARN DAGScheduler: Broadcasting large task binary with size 7.2 MiB\n",
      "23/10/11 02:32:33 WARN DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n",
      "23/10/11 02:32:43 WARN DAGScheduler: Broadcasting large task binary with size 1195.6 KiB\n",
      "23/10/11 02:32:50 WARN DAGScheduler: Broadcasting large task binary with size 13.1 MiB\n",
      "23/10/11 02:32:59 WARN DAGScheduler: Broadcasting large task binary with size 1370.6 KiB\n",
      "23/10/11 02:33:07 WARN DAGScheduler: Broadcasting large task binary with size 16.8 MiB\n",
      "23/10/11 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 1506.9 KiB\n",
      "23/10/11 02:33:27 WARN DAGScheduler: Broadcasting large task binary with size 20.8 MiB\n",
      "23/10/11 02:33:39 WARN DAGScheduler: Broadcasting large task binary with size 1529.2 KiB\n",
      "23/10/11 02:33:47 WARN DAGScheduler: Broadcasting large task binary with size 24.8 MiB\n",
      "23/10/11 02:34:01 WARN DAGScheduler: Broadcasting large task binary with size 1537.5 KiB\n",
      "23/10/11 02:34:10 WARN DAGScheduler: Broadcasting large task binary with size 28.9 MiB\n",
      "23/10/11 02:34:24 WARN DAGScheduler: Broadcasting large task binary with size 1482.8 KiB\n",
      "23/10/11 02:34:31 WARN DAGScheduler: Broadcasting large task binary with size 1992.8 KiB\n",
      "23/10/11 02:34:32 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/10/11 02:34:34 WARN DAGScheduler: Broadcasting large task binary with size 19.9 MiB\n",
      "23/10/11 02:34:36 WARN DAGScheduler: Broadcasting large task binary with size 19.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.3481708910190881\n",
      "accuracy: 0.29993815708101423\n",
      "===============================================\n",
      "Trying maxDepth: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:34:51 WARN DAGScheduler: Broadcasting large task binary with size 1420.2 KiB\n",
      "23/10/11 02:34:55 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:34:59 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/10/11 02:35:05 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/10/11 02:35:14 WARN DAGScheduler: Broadcasting large task binary with size 7.2 MiB\n",
      "23/10/11 02:35:24 WARN DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n",
      "23/10/11 02:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1195.6 KiB\n",
      "23/10/11 02:35:38 WARN DAGScheduler: Broadcasting large task binary with size 13.1 MiB\n",
      "23/10/11 02:35:48 WARN DAGScheduler: Broadcasting large task binary with size 1370.6 KiB\n",
      "23/10/11 02:35:56 WARN DAGScheduler: Broadcasting large task binary with size 16.8 MiB\n",
      "23/10/11 02:36:06 WARN DAGScheduler: Broadcasting large task binary with size 1506.9 KiB\n",
      "23/10/11 02:36:15 WARN DAGScheduler: Broadcasting large task binary with size 20.8 MiB\n",
      "23/10/11 02:36:28 WARN DAGScheduler: Broadcasting large task binary with size 1529.2 KiB\n",
      "23/10/11 02:36:37 WARN DAGScheduler: Broadcasting large task binary with size 24.8 MiB\n",
      "23/10/11 02:36:50 WARN DAGScheduler: Broadcasting large task binary with size 1537.5 KiB\n",
      "23/10/11 02:36:58 WARN DAGScheduler: Broadcasting large task binary with size 28.9 MiB\n",
      "23/10/11 02:37:11 WARN DAGScheduler: Broadcasting large task binary with size 1482.8 KiB\n",
      "23/10/11 02:37:20 WARN DAGScheduler: Broadcasting large task binary with size 32.7 MiB\n",
      "23/10/11 02:37:32 WARN DAGScheduler: Broadcasting large task binary with size 1359.2 KiB\n",
      "23/10/11 02:37:38 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:37:39 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:37:41 WARN DAGScheduler: Broadcasting large task binary with size 22.1 MiB\n",
      "23/10/11 02:37:44 WARN DAGScheduler: Broadcasting large task binary with size 22.1 MiB\n",
      "[Stage 270:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.35109653867141505\n",
      "accuracy: 0.304178814382896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_max_depth(left, right):\n",
    "    if left == right:\n",
    "        return left\n",
    "    left_metric, right_metric = try_depth(left), try_depth(right)\n",
    "    if left_metric['accuracy'] < right_metric['accuracy']:\n",
    "        middle = math.ceil((left + right) / 2)\n",
    "        return find_best_max_depth(middle, right)\n",
    "    else:\n",
    "        middle = math.floor((left + right) / 2)\n",
    "        return find_best_max_depth(left, middle)\n",
    "\n",
    "find_best_max_depth(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79382fed-2f51-4a65-a07e-ae956a114943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:40:28 WARN DAGScheduler: Broadcasting large task binary with size 1432.0 KiB\n",
      "23/10/11 02:40:31 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:40:36 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "23/10/11 02:40:42 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/10/11 02:40:50 WARN DAGScheduler: Broadcasting large task binary with size 7.2 MiB\n",
      "23/10/11 02:40:56 WARN DAGScheduler: Broadcasting large task binary with size 1002.9 KiB\n",
      "23/10/11 02:41:01 WARN DAGScheduler: Broadcasting large task binary with size 10.0 MiB\n",
      "23/10/11 02:41:09 WARN DAGScheduler: Broadcasting large task binary with size 1204.0 KiB\n",
      "23/10/11 02:41:15 WARN DAGScheduler: Broadcasting large task binary with size 13.3 MiB\n",
      "23/10/11 02:41:25 WARN DAGScheduler: Broadcasting large task binary with size 1380.0 KiB\n",
      "23/10/11 02:41:32 WARN DAGScheduler: Broadcasting large task binary with size 17.0 MiB\n",
      "23/10/11 02:41:44 WARN DAGScheduler: Broadcasting large task binary with size 1501.9 KiB\n",
      "23/10/11 02:41:52 WARN DAGScheduler: Broadcasting large task binary with size 20.9 MiB\n",
      "23/10/11 02:42:05 WARN DAGScheduler: Broadcasting large task binary with size 1532.3 KiB\n",
      "23/10/11 02:42:13 WARN DAGScheduler: Broadcasting large task binary with size 24.9 MiB\n",
      "23/10/11 02:42:27 WARN DAGScheduler: Broadcasting large task binary with size 1539.8 KiB\n",
      "23/10/11 02:42:36 WARN DAGScheduler: Broadcasting large task binary with size 29.0 MiB\n",
      "23/10/11 02:42:50 WARN DAGScheduler: Broadcasting large task binary with size 1529.8 KiB\n",
      "23/10/11 02:42:59 WARN DAGScheduler: Broadcasting large task binary with size 32.9 MiB\n",
      "23/10/11 02:43:11 WARN DAGScheduler: Broadcasting large task binary with size 1407.2 KiB\n",
      "23/10/11 02:43:20 WARN DAGScheduler: Broadcasting large task binary with size 36.5 MiB\n",
      "23/10/11 02:43:33 WARN DAGScheduler: Broadcasting large task binary with size 1217.5 KiB\n",
      "23/10/11 02:43:39 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/11 02:43:40 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:43:42 WARN DAGScheduler: Broadcasting large task binary with size 24.4 MiB\n",
      "23/10/11 02:43:49 WARN DAGScheduler: Broadcasting large task binary with size 24.4 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.9710687689872146\n",
      "accuracy: 0.9712219144352109\n",
      "Testing data evaluation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/11 02:43:55 WARN DAGScheduler: Broadcasting large task binary with size 24.2 MiB\n",
      "23/10/11 02:43:57 WARN DAGScheduler: Broadcasting large task binary with size 24.2 MiB\n",
      "[Stage 532:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.3512083659526571\n",
      "accuracy: 0.3031905195989061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rfr = RandomForestClassifier(maxDepth=20, labelCol='SalesQuantity', featuresCol='features', maxBins=256)\n",
    "model = rfr.fit(transformer.transform(train))\n",
    "print_evaluation(model, train, test, 'SalesQuantity', transformer, evaluate_function=evaluate_classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be519801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|            feature|importance|\n",
      "+-------------------+----------+\n",
      "|PurchasePrice_log10|  0.257652|\n",
      "|         DayOfMonth|  0.252801|\n",
      "| VendorNumber_index|  0.191818|\n",
      "|   SalesPrice_log10|   0.17349|\n",
      "|    DayOfWeek_index|   0.12424|\n",
      "+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_feature_importance(model, transformer.transform(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b1c546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|             Brand|             count|\n",
      "+-------+------------------+------------------+\n",
      "|  count|              3798|              3798|\n",
      "|   mean|15094.384149552396|10.172985781990521|\n",
      "| stddev|13184.954924953821| 9.884283717826671|\n",
      "|    min|               100|                 1|\n",
      "|    25%|            3919.0|                 3|\n",
      "|    50%|            8895.0|                 7|\n",
      "|    75%|           23764.0|                15|\n",
      "|    max|               999|                52|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "integrated_sales.groupBy('Brand').agg(F.count('Brand').alias('count')).summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d3218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
